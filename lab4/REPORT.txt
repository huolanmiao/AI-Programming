作业报告
本次作业实现自 动微分

Task1：
Tensor类继承Value类，被运算的数据、运算符和运算结果被储存在Value类中。
每一个运算符是继承了TensorOp的类，实现前向和反向传播，而TensorOp继承Op类实现__call__，返回一个Tensor。
这样实现了Tensor类之间的运算，每一次运算都被记录在新的Tensor中。

在实现运算类前向传播的时候可以使用numpy，因为在构造新Tensor时，cached_data是np.ndarray类型，compute函数只需要得到正确的结果。
在实现反向传播的时候，只能使用Tensor类定义的运算符，这是因为gradient要返回Tensor。

在实现Broadcast反向传播的时候，要将梯度在原先被广播的维度上，求和。summation，则要将梯度在原先被求和的维度上，广播。

Task2：
由于每个Tensor都记录了被运算的数据、运算符和运算结果，如果把output作为运算图的根节点，每个节点都记录其后继节点（子节点）。
在求梯度的时候要做反向传播，需要在计算output到某节点的梯度时，保证该节点所有父节点都计算过，计算顺序可以由逆拓扑排序得到。
在按顺序计算每个变量的梯度时，我们遍历的是父节点，得到的梯度是其子节点的梯度，所以需要按node.inputs这个先前记录的List，计算到每个子节点的梯度。